---
title: "Informative Title Name"
author: "GROUP NUMBER:4 - Uzair Mirza, Krisha Selvakumar, Pranav Sethi, Shruti Sood"
date: May 28, 2021
subtitle: STA304 - Assignment 2
output:
  pdf_document: default
---

```{r, include=FALSE, warning=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
#library(openintro)
library(tidyverse)
library(broom)
library(ggpubr)
library(lme4)
library(brms)
library(survey)
```

```{r, include = FALSE}
# Here we are just loading the data files
census_data <- read_csv("gss_clean.csv")
# Here you can load in the survey data
survey_data <- read_csv("ces2019_clean.csv")
```

## Introduction

<Here you should have a few paragraphs of text introducing the problem, getting the reader interested/ready for the rest of the report.>

<Introduce terminology.>

<Highlight hypotheses.>

<Optional: You can also include a description of each section of this report as a last paragraph.>

<Type here a paragraph introducing the data, its context and as much info about the data collection process that you know.>

<Type here a summary of the cleaning process (**only add in stuff beyond my original gss_cleaning.R code**). You only need to describe additional cleaning that you and your group did.> ]

#Data cleaning
```{r}
#filtering out the required columns
census_data.1 <- select(census_data, 2,12,16,17,19,28,47)
#head(census_data.1)

# adding the place of birth to our data set
census_data.2 <- census_data.1 %>% mutate(place_birth = coalesce(place_birth_macro_region, place_birth_province ))

#[https://stackoverflow.com/questions/14563531/combine-column-to-remove-nas]

# removing the columns for place of birth
census_data.3 <- select(census_data.2, -3,-4)
#view(census_data.3)

# remove the NA
census_data.4 <- na.omit(census_data.3)
```

#Syncing data variables with Census data so that we only have the variables avalible to us
```{r}
## EDUCATION

# combining the "Trade certificate or diploma" +"College, CEGEP or other non-university certificate or di..."
# into "College, CEGEP, trade certificate or other non-university certificate or di..."
  # reason: to sync with the survey data categoery
census_data.4$education <- replace(census_data.4$education, census_data.4$education ==
                                     "College, CEGEP or other non-university certificate or di...",
                                   "College, CEGEP, trade certificate or other non-university certificate or di...")
census_data.4$education <- replace(census_data.4$education, census_data.4$education ==
                                     "Trade certificate or diploma", "College, CEGEP, trade certificate or other non-university certificate or di...")

## Age

# we drop the decimal point to stay consistent with the survey

census_data.4$age <- floor(census_data.4$age)
#https://stackoverflow.com/questions/40399255/remove-decimals-from-a-column-in-a-data-frame
```

#Dropping the columns in the census data which are not present in the survey data 
```{r}
#census_data.8 <- census_data.7 %>%
 # select(sex, province, feelings_life, education, religion_participation, age, income_family)

```

## Data Analysis
```{r}

mytable.1 <- table(survey_data$sex)
lbls.1 <- paste(names(mytable.1), "\n", mytable.1, sep="")

mytable.2 <- table(census_data$sex)
lbls.2 <- paste(names(mytable.2), "\n", mytable.2, sep="")

# Pie Chart from data frame with Appended Sample Sizes                              [https://www.statmethods.net/graphs/pie.html]
# spreads of Sex, pie chart
#ggarrange(
  
#pie(mytable.1, labels = lbls.1,
  # main="Sex in Survey"),
#pie(mytable.2, labels = lbls.2,
  # main="Sex in Census"), ncol=2, nrow=1
#)

# Spreads of Sex
ggarrange(
ggplot(survey_data, aes(x=sex ))+
  geom_bar(color="darkblue", fill="lightblue", bins = 40) +
  ggtitle("Spread of Sex in Survey"),

ggplot(census_data.4, aes(x=sex))+
  geom_bar(color="darkblue", fill="lightblue", bins = 40) +
  ggtitle("Spread of Sex in Census"),
 ncol=2, nrow=1)

# Spread of Province                          ##----FIX THE LABLES-----##
ggarrange(
ggplot(survey_data, aes(x=province ))+
  geom_bar(color="darkblue", fill="lightblue", bins = 40) +
  ggtitle("Spread of Province in Survey"),

ggplot(census_data.4, aes(x=province))+
  geom_bar(color="darkblue", fill="lightblue", bins = 50) +
  ggtitle("Spread of Province in Census"),
 ncol=2, nrow=1)

# Spread of ages
ggarrange(
ggplot(survey_data, aes(x=age ))+
  geom_histogram(color="darkblue", fill="lightblue", bins = 40) +
  ggtitle("Spread of Ages in Survey"),

ggplot(census_data.4, aes(x=age))+
  geom_histogram(color="darkblue", fill="lightblue", bins = 50) +
  ggtitle("Spread of Ages in Census"),
 ncol=2, nrow=1)

# Spread of family income                      ----FIX AXIS or Pie Chart----
ggarrange(
ggplot(survey_data, aes(x=income_family ))+
  geom_bar(color="darkblue", fill="lightblue", bins = 40) +
  ggtitle("Spread of Family's incomes in Survey"),

ggplot(census_data.4, aes(x=income_family))+
  geom_bar(color="darkblue", fill="lightblue", bins = 50) +
  ggtitle("Spread of Family's incomes in Census"),
 ncol=2, nrow=1)

# get the frequency for each variable using 
table(census_data.4$province)
```

#Model ideas

## making the data sets to make models
```{r}

## make the according data sets according to the Support of their party               ---WITH AGE GROUPS
NDP_predic <- survey_data %>%
  mutate(NDP_pref = case_when( survey_data$political_pref == "NDP (New Democratic Party, New Democrats, NDPers)" ~ 1,
                              survey_data$political_pref != "NDP (New Democratic Party, New Democrats, NDPers)" ~ 0))

## Bloc Québécois (BQ, PQ, Bloc, Parti Québécois)
Bloc_predic <- survey_data %>%
  mutate(Bloc_pref = case_when(survey_data$political_pref == "Bloc Québécois (BQ, PQ, Bloc, Parti Québécois)" ~ 1,
                              survey_data$political_pref != "Bloc Québécois (BQ, PQ, Bloc, Parti Québécois)" ~ 0))

## Green Party (Greens)
Green_predic <- survey_data %>%
  mutate(Green_pref = case_when(survey_data$political_pref == "Green Party (Greens)" ~ 1,
                              survey_data$political_pref != "Green Party (Greens)"  ~ 0))

## Conservatives (Tory, PCs, Conservative Party of Canada)
Conservative_predic <- survey_data %>%
  mutate(Conservative_pref = case_when(survey_data$political_pref == "Conservatives (Tory, PCs, Conservative Party of Canada)" ~ 1,
                              survey_data$political_pref != "Conservatives (Tory, PCs, Conservative Party of Canada)"  ~ 0))

## Liberal (Grits)
Liberal_predic <- survey_data %>%
  mutate(Liberal_pref = case_when(survey_data$political_pref == "Liberal (Grits)" ~ 1,
                              survey_data$political_pref != "Liberal (Grits)"  ~ 0))

## People's Party
Liberal_predic <- survey_data %>%
  mutate(People_pref = case_when(survey_data$political_pref == "People's Party" ~ 1,
                              survey_data$political_pref != "People's Party"  ~ 0))

## Will spoil ballet
Spoil_pred <- survey_data %>%
  mutate(People_pref = case_when(survey_data$political_pref == "Will spoil ballet" ~ 1,
                              survey_data$political_pref != "Will spoil ballet"  ~ 0))

## Other
Other_pred <- survey_data %>%
  mutate(Other_pref = case_when(survey_data$political_pref == "Other" ~ 1,
                              survey_data$political_pref != "Other"  ~ 0))

```

###Possible Model
```{r}

n = length(survey_data$political_pref)
N = 37.59 * 10^6

## Using the Survey Library
fpc.srs = rep(N, n)

## running estimated logistic regression model
design.NDP <- svydesign(id=~1, data=NDP_predic, fpc=fpc.srs)



# running logistic regression model         ----High p-values---
glm_NDP_model.1<-glm(NDP_pref ~ sex + education + age + income_family + province, data=NDP_predic, family="binomial")
summary(glm_NDP_model.1)
tidy(glm_NDP_model.1) -> glm_NDP_res.1
view(glm_NDP_res.1)

# running multilevel logistic regression model                ------!!!! +  age !!!!!causing error, p-values -----
glm_NDP_model.2<-glmer(NDP_pref ~ sex + education +  income_family +  age + (1|province), data=NDP_predic, family=binomial)
                                                        # religion_participation + age + income_family
summary(glm_NDP_model.2)
#tidy(glm_NDP_model.2) -> glm_NDP_res.2
#view(glm_NDP_res.2)

# just




##Baysian how to know which model is much better?
                         
# running a baysian logestic regression model
brm_NDP_model.1 <- brm(NDP_pref ~ sex + education + age + income_family + province, data=NDP_predic, family=bernoulli())
summary(brm_NDP_model.1)

# running a baysian logestic multilevel regression model
brm_NDP_model.2 <- brm(NDP_pref ~ sex + education + age + income_family + (1|province), data=NDP_predic, family=bernoulli())
summary(brm_NDP_model.2)


### to DO's
## need the population size for each provience
## Do post strat based on Provience

## estimate the Y_hat for each party using log regression, repeat above for each party and see the leader
```

##Estimate Calculation    
```{r}
# predict

X <- predict(glm_NDP_model.2, census_data.4)
view(X)

est_p <- function(sum){
  return(exp(sum)/1+(exp(sum)))
}




# sum of estimate \log(p\1-p) = 
sum <- function(x1,x2,x3,x4,x5,x6,x7){
  estimate_sum = 0.203166 + -0.540797*x1 + -0.082159*x2 + -0.168995*x3 + -1.780165*x4 + 0.356030*x5 + 0.228831*x6 + -0.036131*x7
  return(estimate_sum)
}



```


# grouping based on age 
```{r}
#removing ppl less than 18
 census_data.44 <- subset(census_data.4, age >18)
  #census_data.4[census_data.4$age > 18, ]

# age group for census data
census_data.5 <- census_data.44 %>%
 mutate(age_group = case_when(census_data.44$age <18 ~ "Under 18",
                              census_data.44$age <25 ~ "18 to 24 years",
                              census_data.44$age <45 ~ "25 to 44 years",
                              census_data.44$age <65 ~ "45 to 64 years",
                              census_data.44$age >64 ~ "Over 65",
                              ))
# dropping place of birth and their age
census_data.6 <- select(census_data.5, -6, -1)


# survey data grouping based on age
survey_data.1 <- survey_data %>%
 mutate(age_group = case_when(survey_data$age <18 ~ "Under 18",
                              survey_data$age <25 ~ "18 to 24 years",
                              survey_data$age <45 ~ "25 to 44 years",
                              survey_data$age <65 ~ "45 to 64 years",
                              survey_data$age >64 ~ "Over 65",
                              ))

# removing feeling life, religion participation, age
survey_data.2 <- select(survey_data.1, -3, -6)
survey_data.2 <- select(survey_data.2, -5)

# catoger the age groups for model
NDP_predic.1 <- survey_data.2 %>%
  mutate(NDP_pref = case_when(survey_data.2$political_pref == "NDP (New Democratic Party, New Democrats, NDPers)" ~ 1,
                              survey_data.2$political_pref != "NDP (New Democratic Party, New Democrats, NDPers)" ~ 0))

# group the survey data by the provience filter out Alberta ppl
AlbertaXsurveyXNDP <- NDP_predic.1 %>% group_by(province = "Alberta")
# make the model
glm_NDP_model.2<-glmer(NDP_pref ~ sex + education + (1|income_family) + age_group, data=AlbertaXsurveyXNDP, family=binomial)
#results
summary(glm_NDP_model.2)

## assign bins and get the counts for the census data
# filter out for Alberta
albertaXcensus <- census_data.5 %>% group_by(province = "Alberta")
# get the bin count
albertaXcensus.1 <- albertaXcensus %>%
  count(sex, education,  income_family, age_group)

# make the prediction
X <- predict(glm_NDP_model.2, albertaXcensus.1)
view(X)


# prob function
est_p <- function(sum){
  return(exp(sum)/(1+(exp(sum))))
}

# getting the probability of ppl voting for NDPxAlberta
albertaXcensus.1$NDP_odds <- X

#albertaXcensus.11 <- select(albertaXcensus.1, -1)

# getting the probability for each group
albertaXcensus.1 <- albertaXcensus.1 %>% mutate(prob_NDP = est_p(NDP_odds))


# post-strart stuff
## sum of N
N <- sum(albertaXcensus.1$n)

# prediction for NDPxAlberta
test <- albertaXcensus.1 %>% summarise(est = (sum(n*prob_NDP)/N))





# make the modle based on the new data catogeries
glm_NDP_model.2<-glmer(NDP_pref ~ sex+ (1|province)+ education+ income_family+age_group , data=NDP_predic.1, family=binomial)
summary(glm_NDP_model.2)


 

##S3 assign bins

# assign bins and get the counts
census_data.7 <- census_data.6 %>%
  count(sex, province, education,  income_family, age_group)


# now predict for each bin
X <- predict(glm_NDP_model.2, census_data.7)
view(X)




# filter based on provience

#

  group_by(age_group = , )




```



#Grouping based on proviences
```{r}
# make them in groups by province
alberta <- census_data.4 %>% group_by(province = "Alberta")
british_columbia <- census_data.4 %>% group_by(province = "British Columbia")
manitoba<- census_data.5 %>% group_by(province = "Manitoba")
new_brunswick<- census_data.5 %>% group_by(province = "New Brunswick")
newfoundland_labrador<- census_data.5 %>% group_by(province = "Newfoundland and Labrador")
nova_scotia<- census_data.5 %>% group_by(province = "Nova Scotia")
ontario <- census_data.5 %>% group_by(province = "Ontario")
prince_edward_island<- census_data.5 %>% group_by(province = "Prince Edward Island")
quebec<- census_data.5 %>% group_by(province = "Quebec")
saskatchewan<- census_data.5 %>% group_by(province = "Saskatchewan")


```



#Predicting results based on proviences
## NDPxAlberta
```{r}
#people who support NDP in Alberta


# calculating the log odds
X <- predict(glm_NDP_model.2, alberta)
view(alberta)

# adding the log odds
alberta$predictionXNDp <- tibble(X)

# geeting the prediction results






# get the model for the prediction for 



```



```{r, include = FALSE}

#### You will need to update/clean the code below based off the variables you want to use in your post stratification.
view(sen) 
survey_data <- 
  survey_data %>% 
  mutate(age = 2019-q2,
         vote_liberal = ifelse(q11==1, 1, 0)) %>% 
  select(age, vote_liberal)

census_data <- census_data %>% 
  mutate(age=round(age)) %>% 
  select(age)

```

<Remember, you may want to use multiple datasets here, if you do end up using multiple data sets, or merging the data, be sure to describe this in the cleaning process and be sure to discuss important aspects of all the data that you used.>

<Include a description of the important variables.> 

```{r, include=FALSE}

# Use this to calculate some summary measures. 

```

<Include a description of the numerical summaries. Remember you can use `r ` to use inline R code.>

```{r, echo = TRUE}

# Use this to create some plots. Should probably describe both the sample and population.

```

<Include a clear description of the plot(s). I would recommend one paragraph for each plot.> 

## Methods

<Include some text introducing the methodology, maybe restating the problem/goal of this analysis.>

### Model Specifics
<Here you can describe your regression model>

<I will (incorrectly) be using a linear regression model to model the proportion of voters who will vote for Donald Trump. This is a naive model. I will only be using age, which is recorded as a numeric variable, to model the probability of voting for Donald Trump. The simple linear regression model I am using is:> 

$$ y = \beta_0+\beta_1  x_{age} + \epsilon$$

<Where $y$ represents the ....  $\beta_0$ represents....>

```{r, include=FALSE}

# Creating the Model
model <- lm(vote_liberal ~ age, data=survey_data)

# Model Results (to Report in Results section)
# summary(model)
# OR
# broom::tidy(model)

### Don't show the results/output here...

```

## Post-Stratification 

<Here you should explain the poststratification process>

<In order to estimate the proportion of voters.....>

<To put math/LaTeX inline just use one set of dollar signs. Example: $\hat{y}^{PS}$ >

<To put math on its own line use two sets of dollar signs:>

$$ include.your.mathematical.model.here.if.you.have.some.math.to.show $$
All analysis for this report was programmed using `R version 4.0.2`. 

## Results 

```{r, include=FALSE}

# Creating the Model
model <- lm(vote_liberal ~ age, data=survey_data)

# Model Results (to Report in Results section)
# summary(model)
# OR
# broom::tidy(model)
```

```{r, include=FALSE}

glm_NDP_model.22<-glmer(NDP_pref ~ sex + feelings_life +religion_participation+ education + (1|province), data=NDP_predic, family=binomial)
  
# Here I will perform the post-stratification calculation
census_data_counts <- census_data %>% 
  group_by(age) %>% 
  summarise(n=n())

census_data_counts$estimate <-
  model %>%
  predict(newdata = census_data_counts)

census_data_counts %>% 
  mutate(liberal_predict_prop = estimate*n) %>%
  summarise(liberal_predict = sum(liberal_predict_prop)/sum(n))
```

<Here you present your results. You may want to put them into a well formatted table. Be sure that there is some text describing the results.>

<Note: Alternatively you can use the `knitr::kable` function to create a well formatted table from your code. See here: [https://rmarkdown.rstudio.com/lesson-7.html](https://rmarkdown.rstudio.com/lesson-7.html).>

<Remember you can use `r ` to use inline R code.>

```{r, include = FALSE}

# Here you can include some relevant visualizations.
```

<Include an explanation/interpretation of the visualizations. Make sure to comment on the appropriateness of the assumptions/results.>

## Conclusions

## Drawbacks
                                                                      **relevant fields not found in the survey, provinces((11) Northwest Territories, (12) Yukon, (13) Nunavut)**

<Here you should give a summary of the Hypotheses, Methods and Results>

<Highlight Key Results.>

<Talk about big picture.>

<Comment on any Weaknesses.>

<Comment on Future Work/Next Steps>

<End with a concluding paragraph to wrap up the report.>

## Bibliography

1. Grolemund, G. (2014, July 16) *Introduction to R Markdown*. RStudio. [https://rmarkdown.rstudio.com/articles_intro.html](https://rmarkdown.rstudio.com/articles_intro.html). (Last Accessed: January 15, 2021) 

2. Dekking, F. M., et al. (2005) *A Modern Introduction to Probability and Statistics: Understanding why and how.* Springer Science & Business Media.

3.  Allaire, J.J., et. el. *References: Introduction to R Markdown*. RStudio. [https://rmarkdown.rstudio.com/docs/](https://rmarkdown.rstudio.com/docs/). (Last Accessed: January 15, 2021) 
